{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfdd972a",
   "metadata": {},
   "source": [
    "## Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41626edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from typing import Dict, List, Any\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "# Import from the package\n",
    "try:\n",
    "    from llm_auction_optimization import (\n",
    "        ClinicalVignette,\n",
    "        PrivateAssessment,\n",
    "        AuctionResult,\n",
    "        Intervention,\n",
    "        RoundOutcome,\n",
    "        AgentState,\n",
    "        run_auction,\n",
    "        ExperimentConfig,\n",
    "        ExperimentLogger,\n",
    "        ExperimentMetrics,\n",
    "        MetricsDisplay,\n",
    "    )\n",
    "except ImportError as e:\n",
    "    print(f\"Note: Could not import from package. Will use inline implementations.\")\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "# Set style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"✓ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d607af75",
   "metadata": {},
   "source": [
    "## Part 1: Create Mock Clinical Vignettes\n",
    "\n",
    "For MVP, we'll use synthetic vignettes. In production, these come from the Ethical Reasoning in Mental Health HuggingFace dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80e9a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mock clinical vignettes for demo\n",
    "mock_vignettes = [\n",
    "    {\n",
    "        'id': 'V1',\n",
    "        'text': '32-year-old male presents with fever (39°C), cough, and dyspnea for 3 days. CXR shows left lower lobe infiltrate. No significant PMHx.',\n",
    "        'options': ['Pneumonia', 'Bronchitis', 'Asthma exacerbation', 'Pulmonary embolism'],\n",
    "        'ground_truth': 'Pneumonia',\n",
    "        'triage': 'ER',\n",
    "    },\n",
    "    {\n",
    "        'id': 'V2',\n",
    "        'text': '58-year-old female with chest pain, dyspnea, and diaphoresis. EKG shows ST elevation in II, III, aVF.',\n",
    "        'options': ['Acute MI', 'Unstable angina', 'Aortic dissection', 'Pneumonia'],\n",
    "        'ground_truth': 'Acute MI',\n",
    "        'triage': 'ER',\n",
    "    },\n",
    "    {\n",
    "        'id': 'V3',\n",
    "        'text': '24-year-old female with mild headache and no fever. Exam unremarkable. Works in busy office.',\n",
    "        'options': ['Migraine', 'Tension headache', 'Meningitis', 'Subarachnoid hemorrhage'],\n",
    "        'ground_truth': 'Tension headache',\n",
    "        'triage': 'Routine',\n",
    "    },\n",
    "    {\n",
    "        'id': 'V4',\n",
    "        'text': '45-year-old male with acute onset severe abdominal pain, vomiting. Fever 38.5°C. Rebound tenderness.',\n",
    "        'options': ['Appendicitis', 'Gastroenteritis', 'Pancreatitis', 'Diverticulitis'],\n",
    "        'ground_truth': 'Appendicitis',\n",
    "        'triage': 'ER',\n",
    "    },\n",
    "    {\n",
    "        'id': 'V5',\n",
    "        'text': '72-year-old female with chronic leg swelling. No acute pain. Ambulatory. Mild weight gain.',\n",
    "        'options': ['DVT', 'Cellulitis', 'Venous insufficiency', 'Lymphedema'],\n",
    "        'ground_truth': 'Venous insufficiency',\n",
    "        'triage': 'Routine',\n",
    "    },\n",
    "]\n",
    "\n",
    "# Convert to ClinicalVignette objects\n",
    "vignettes = [\n",
    "    ClinicalVignette(\n",
    "        vignette_id=v['id'],\n",
    "        text=v['text'],\n",
    "        ground_truth_action=v['ground_truth'],\n",
    "        options=v['options'],\n",
    "        task_type='diagnosis',\n",
    "        metadata={'triage': v['triage']}\n",
    "    )\n",
    "    for v in mock_vignettes\n",
    "]\n",
    "\n",
    "print(f\"Created {len(vignettes)} clinical vignettes\")\n",
    "print(\"\\nExample vignette:\")\n",
    "print(f\"  ID: {vignettes[0].vignette_id}\")\n",
    "print(f\"  Text: {vignettes[0].text}\")\n",
    "print(f\"  Ground truth: {vignettes[0].ground_truth_action}\")\n",
    "print(f\"  Options: {vignettes[0].options}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d28c3a9",
   "metadata": {},
   "source": [
    "## Part 2: Define Mock Agents\n",
    "\n",
    "In production, these would call actual LLMs. For MVP, we use mock agents with synthetic behavior patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1680cfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MockClinicalAgent:\n",
    "    \"\"\"Mock agent that simulates LLM behavior for clinical decision-making.\"\"\"\n",
    "    \n",
    "    def __init__(self, agent_id: str, style: str = 'neutral'):\n",
    "        self.agent_id = agent_id\n",
    "        self.style = style\n",
    "        self.budget = 1.0\n",
    "        self.state = AgentState(\n",
    "            agent_id=agent_id,\n",
    "            initial_budget=1.0,\n",
    "            remaining_budget=1.0,\n",
    "            communication_style=style\n",
    "        )\n",
    "    \n",
    "    def assess(self, vignette: ClinicalVignette) -> PrivateAssessment:\n",
    "        \"\"\"Independently assess the vignette.\"\"\"\n",
    "        # Mock: deterministic but with noise based on style\n",
    "        np.random.seed(hash(self.agent_id + vignette.vignette_id) % 2**32)\n",
    "        \n",
    "        # Correct answer with some probability\n",
    "        if np.random.random() < 0.6:  # 60% accuracy baseline\n",
    "            action = vignette.ground_truth_action\n",
    "        else:\n",
    "            action = np.random.choice([a for a in vignette.options if a != vignette.ground_truth_action])\n",
    "        \n",
    "        # Confidence based on style\n",
    "        if self.style == 'overconfident':\n",
    "            confidence = min(0.95, np.random.normal(0.8, 0.1))\n",
    "        elif self.style == 'underconfident':\n",
    "            confidence = max(0.3, np.random.normal(0.5, 0.1))\n",
    "        else:\n",
    "            confidence = np.clip(np.random.normal(0.65, 0.15), 0.3, 0.95)\n",
    "        \n",
    "        # Rationale (mock)\n",
    "        rationale = f\"• Key finding: {vignette.text.split()[0:5]}\\n• Differential: {action} or alternative\\n• Recommendation: {action}\"\n",
    "        \n",
    "        return PrivateAssessment(\n",
    "            agent_id=self.agent_id,\n",
    "            recommended_action=action,\n",
    "            confidence=float(confidence),\n",
    "            rationale=rationale\n",
    "        )\n",
    "    \n",
    "    def bid(self, assessment: PrivateAssessment) -> float:\n",
    "        \"\"\"Decide how much to bid for proposal rights.\"\"\"\n",
    "        # Bid based on confidence and style\n",
    "        base_bid = min(self.budget, assessment.confidence * 0.5)\n",
    "        \n",
    "        if self.style == 'assertive':\n",
    "            bid = base_bid * 1.3\n",
    "        elif self.style == 'timid':\n",
    "            bid = base_bid * 0.7\n",
    "        else:\n",
    "            bid = base_bid\n",
    "        \n",
    "        return min(self.budget, bid)  # Cap at budget\n",
    "    \n",
    "    def should_speak(self, proposer_action: str, vignette: ClinicalVignette, p=0.4) -> bool:\n",
    "        \"\"\"Decide whether to pay to speak.\"\"\"\n",
    "        # Speak if proposer might be wrong\n",
    "        if self.style == 'cooperative':\n",
    "            return np.random.random() < (p * 1.3)\n",
    "        elif self.style == 'competitive':\n",
    "            return np.random.random() < (p * 0.7)\n",
    "        else:\n",
    "            return np.random.random() < p\n",
    "    \n",
    "    def vote(self, all_options: Dict[str, str], vignette: ClinicalVignette) -> str:\n",
    "        \"\"\"Vote on best option.\"\"\"\n",
    "        # Vote for own if available, else random\n",
    "        if self.agent_id in all_options:\n",
    "            if self.style == 'competitive':\n",
    "                return all_options[self.agent_id]  # Always vote for self\n",
    "        # Random vote among options\n",
    "        return np.random.choice(list(all_options.values()))\n",
    "\n",
    "print(\"✓ MockClinicalAgent defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d25694d",
   "metadata": {},
   "source": [
    "## Part 3: Implement Core Auction Game Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b58fab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_clinical_auction_round(\n",
    "    agents: List[MockClinicalAgent],\n",
    "    vignette: ClinicalVignette,\n",
    "    token_price: float = 0.001,\n",
    "    reward_amount: float = 1.0,\n",
    "    auction_type: str = 'sealed_bid',\n",
    "    round_id: int = 0\n",
    ") -> RoundOutcome:\n",
    "    \"\"\"\n",
    "    Run one complete auction round for clinical decision-making.\n",
    "    \"\"\"\n",
    "    \n",
    "    # ROUND 0: Private Assessment\n",
    "    private_assessments = {}\n",
    "    for agent in agents:\n",
    "        assessment = agent.assess(vignette)\n",
    "        private_assessments[agent.agent_id] = assessment\n",
    "    \n",
    "    # ROUND 1: Sealed-Bid Auction for Proposer Rights\n",
    "    bids = {}\n",
    "    for agent in agents:\n",
    "        bid = agent.bid(private_assessments[agent.agent_id])\n",
    "        bids[agent.agent_id] = min(bid, agent.state.remaining_budget)\n",
    "    \n",
    "    # Run auction\n",
    "    proposer_id, proposer_cost = run_auction(bids, auction_type, {a.agent_id: a.state.remaining_budget for a in agents})\n",
    "    \n",
    "    # Deduct bid cost\n",
    "    for agent in agents:\n",
    "        if agent.agent_id == proposer_id:\n",
    "            agent.state.remaining_budget -= proposer_cost\n",
    "            agent.state.total_bids_paid += proposer_cost\n",
    "    \n",
    "    proposer_assessment = private_assessments[proposer_id]\n",
    "    \n",
    "    # ROUND 2: Optional Paid Interventions\n",
    "    interventions = []\n",
    "    all_options = {proposer_id: proposer_assessment.recommended_action}\n",
    "    \n",
    "    for agent in agents:\n",
    "        if agent.agent_id != proposer_id:\n",
    "            if agent.should_speak(proposer_assessment.recommended_action, vignette):\n",
    "                # Generate a mock message\n",
    "                message = f\"I suggest {np.random.choice(vignette.options)}\"\n",
    "                token_count = len(message.split())\n",
    "                speaking_cost = token_count * token_price\n",
    "                \n",
    "                if speaking_cost <= agent.state.remaining_budget:\n",
    "                    agent.state.remaining_budget -= speaking_cost\n",
    "                    agent.state.total_tokens_used += token_count\n",
    "                    agent.state.interventions_made += 1\n",
    "                    \n",
    "                    # Extract alternative action from message\n",
    "                    alt_action = message.split()[-1]  # Last word\n",
    "                    if alt_action in vignette.options:\n",
    "                        all_options[agent.agent_id] = alt_action\n",
    "                    \n",
    "                    interventions.append(Intervention(\n",
    "                        agent_id=agent.agent_id,\n",
    "                        message=message,\n",
    "                        token_count=token_count,\n",
    "                        cost=speaking_cost,\n",
    "                        suggested_alternative_action=alt_action if alt_action in vignette.options else None\n",
    "                    ))\n",
    "    \n",
    "    # ROUND 3: Vote\n",
    "    votes = {}\n",
    "    for agent in agents:\n",
    "        vote = agent.vote(all_options, vignette)\n",
    "        votes[agent.agent_id] = vote\n",
    "    \n",
    "    # Majority vote\n",
    "    vote_counts = Counter(votes.values())\n",
    "    final_action = vote_counts.most_common(1)[0][0]\n",
    "    \n",
    "    # ROUND 4: Evaluate & Payoff\n",
    "    correctness = (final_action == vignette.ground_truth_action)\n",
    "    \n",
    "    agent_rewards = {}\n",
    "    for agent in agents:\n",
    "        agent.state.rounds_participated += 1\n",
    "        \n",
    "        if agent.agent_id == proposer_id:\n",
    "            agent.state.times_proposer += 1\n",
    "            if proposer_assessment.recommended_action == vignette.ground_truth_action:\n",
    "                agent.state.times_proposer_correct += 1\n",
    "        \n",
    "        if correctness:\n",
    "            reward = reward_amount\n",
    "            \n",
    "            # Bonus for helpful interventions\n",
    "            for intervention in interventions:\n",
    "                if intervention.agent_id == agent.agent_id and intervention.suggested_alternative_action == vignette.ground_truth_action:\n",
    "                    reward += 0.25\n",
    "                    agent.state.interventions_valuable += 1\n",
    "        else:\n",
    "            reward = 0.0\n",
    "        \n",
    "        agent.state.cumulative_reward += reward\n",
    "        agent_rewards[agent.agent_id] = reward\n",
    "    \n",
    "    # Compute totals\n",
    "    total_tokens = sum(i.token_count for i in interventions)\n",
    "    total_cost = proposer_cost + sum(i.cost for i in interventions)\n",
    "    \n",
    "    # Create outcome\n",
    "    outcome = RoundOutcome(\n",
    "        timestamp=datetime.now(),\n",
    "        vignette=vignette,\n",
    "        round_id=round_id,\n",
    "        private_assessments=private_assessments,\n",
    "        auction_result=AuctionResult(\n",
    "            proposer_id=proposer_id,\n",
    "            proposer_bid=bids[proposer_id],\n",
    "            all_bids=bids\n",
    "        ),\n",
    "        interventions=interventions,\n",
    "        votes=votes,\n",
    "        final_action=final_action,\n",
    "        ground_truth_action=vignette.ground_truth_action,\n",
    "        correctness=correctness,\n",
    "        total_tokens=total_tokens,\n",
    "        total_cost=total_cost,\n",
    "        agent_rewards=agent_rewards\n",
    "    )\n",
    "    \n",
    "    return outcome\n",
    "\n",
    "print(\"✓ Game loop implemented\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71d36b3",
   "metadata": {},
   "source": [
    "## Part 4: Run MVP Demo\n",
    "\n",
    "Let's run a few vignettes with the auction mechanism and compare against a baseline (free discussion)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821beaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create agents with different styles\n",
    "styles = ['assertive', 'timid', 'overconfident', 'cooperative', 'neutral']\n",
    "agents = [MockClinicalAgent(f'Agent_{i+1}', style=styles[i]) for i in range(5)]\n",
    "\n",
    "print(\"Agents created:\")\n",
    "for agent in agents:\n",
    "    print(f\"  {agent.agent_id}: {agent.style}\")\n",
    "\n",
    "# Run auction condition on first 3 vignettes\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Running AUCTION condition (budgeted communication)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "auction_outcomes = []\n",
    "for i, vignette in enumerate(vignettes[:3]):\n",
    "    # Reset agents for next round\n",
    "    for agent in agents:\n",
    "        agent.state.remaining_budget = 1.0\n",
    "    \n",
    "    outcome = run_clinical_auction_round(\n",
    "        agents=agents,\n",
    "        vignette=vignette,\n",
    "        token_price=0.001,\n",
    "        reward_amount=1.0,\n",
    "        auction_type='sealed_bid',\n",
    "        round_id=i\n",
    "    )\n",
    "    auction_outcomes.append(outcome)\n",
    "    \n",
    "    print(f\"\\nVignette {i+1}: {vignette.vignette_id}\")\n",
    "    print(f\"  Ground truth: {vignette.ground_truth_action}\")\n",
    "    print(f\"  Proposer: {outcome.auction_result.proposer_id} (bid: ${outcome.auction_result.proposer_bid:.4f})\")\n",
    "    print(f\"  Proposer action: {outcome.private_assessments[outcome.auction_result.proposer_id].recommended_action}\")\n",
    "    print(f\"  Interventions: {len(outcome.interventions)}\")\n",
    "    print(f\"  Final action: {outcome.final_action}\")\n",
    "    print(f\"  Correct: {outcome.correctness}\")\n",
    "    print(f\"  Total cost: ${outcome.total_cost:.4f} (tokens: {outcome.total_tokens})\")\n",
    "\n",
    "print(\"\\n✓ Auction demo complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a642f49",
   "metadata": {},
   "source": [
    "## Part 5: Results & Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbca09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute metrics for auction condition\n",
    "metrics_auction = ExperimentMetrics.compute_metrics(auction_outcomes)\n",
    "agent_stats = ExperimentMetrics.compute_agent_stats({a.agent_id: a.state for a in agents})\n",
    "\n",
    "print(\"\\nAuction Condition Metrics:\")\n",
    "for key, value in metrics_auction.items():\n",
    "    if isinstance(value, float):\n",
    "        print(f\"  {key}: {value:.3f}\")\n",
    "    else:\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\nPer-Agent Stats:\")\n",
    "for agent_id, stats in agent_stats.items():\n",
    "    print(f\"\\n  {agent_id}:\")\n",
    "    print(f\"    Rounds: {stats['rounds_participated']}\")\n",
    "    print(f\"    Times proposer: {stats['times_proposer']}\")\n",
    "    print(f\"    Interventions: {stats['interventions_made']}\")\n",
    "    print(f\"    Net reward: ${stats['cumulative_reward']:.2f}\")\n",
    "    print(f\"    Tokens used: {stats['total_tokens_used']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945c6eec",
   "metadata": {},
   "source": [
    "## Part 6: Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f541adae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# 1. Correctness over rounds\n",
    "ax = axes[0, 0]\n",
    "correctness = [o.correctness for o in auction_outcomes]\n",
    "ax.plot(range(len(correctness)), correctness, marker='o', linewidth=2, markersize=8)\n",
    "ax.set_xlabel('Vignette')\n",
    "ax.set_ylabel('Correct')\n",
    "ax.set_title('Correctness Over Rounds (Auction)')\n",
    "ax.set_ylim(-0.1, 1.1)\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# 2. Cost per round\n",
    "ax = axes[0, 1]\n",
    "costs = [o.total_cost for o in auction_outcomes]\n",
    "ax.bar(range(len(costs)), costs, color='steelblue', alpha=0.7)\n",
    "ax.set_xlabel('Vignette')\n",
    "ax.set_ylabel('Total Cost ($)')\n",
    "ax.set_title('Communication Cost per Round')\n",
    "ax.grid(alpha=0.3, axis='y')\n",
    "\n",
    "# 3. Agent participation\n",
    "ax = axes[1, 0]\n",
    "agent_ids = [a.agent_id for a in agents]\n",
    "interventions = [agent_stats[a]['interventions_made'] for a in agent_ids]\n",
    "ax.bar(agent_ids, interventions, color='coral', alpha=0.7)\n",
    "ax.set_xlabel('Agent')\n",
    "ax.set_ylabel('Interventions Made')\n",
    "ax.set_title('Agent Participation (Paid Interventions)')\n",
    "ax.grid(alpha=0.3, axis='y')\n",
    "\n",
    "# 4. Agent rewards\n",
    "ax = axes[1, 1]\n",
    "rewards = [agent_stats[a]['cumulative_reward'] for a in agent_ids]\n",
    "colors = ['green' if r > 0 else 'red' for r in rewards]\n",
    "ax.bar(agent_ids, rewards, color=colors, alpha=0.7)\n",
    "ax.set_xlabel('Agent')\n",
    "ax.set_ylabel('Net Reward ($)')\n",
    "ax.set_title('Cumulative Agent Rewards')\n",
    "ax.axhline(y=0, color='black', linestyle='-', linewidth=0.5)\n",
    "ax.grid(alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('auction_demo.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Visualization saved to auction_demo.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4885ef1b",
   "metadata": {},
   "source": [
    "## Next Steps for Full Implementation\n",
    "\n",
    "This MVP demonstrates the core game mechanics. To scale up:\n",
    "\n",
    "1. **Load Real Dataset**: Use Ethical Reasoning in Mental Health from HuggingFace\n",
    "2. **Integrate Real LLMs**: Replace mock agents with OpenAI API or local models (Qwen, Llama)\n",
    "3. **Run Baselines**: Implement free-discussion and turn-taking conditions\n",
    "4. **Token Price Sweep**: Run experiments across multiple token prices (0.0001 to 0.01)\n",
    "5. **Generate Results Plots**: Accuracy vs Cost across conditions\n",
    "6. **Analyze Safety**: Count safety interventions that prevented harmful decisions\n",
    "\n",
    "See `DESIGN.md` for detailed implementation guidance."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
